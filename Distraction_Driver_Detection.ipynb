{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Given the dataset consisting of driver images in car and corresponding labels for 10 nos. categories (e.g. safe driving, texting, talking etc.), your task is to build a classification model to predict the category for that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset link: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is data set link:- https://www.kaggle.com/c/state-farm-distracted-driver-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-10T07:02:02.063686Z",
     "iopub.status.busy": "2021-10-10T07:02:02.063034Z",
     "iopub.status.idle": "2021-10-10T07:02:02.091721Z",
     "shell.execute_reply": "2021-10-10T07:02:02.089381Z",
     "shell.execute_reply.started": "2021-10-10T07:02:02.063589Z"
    },
    "id": "nMqeXth21Zgi"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqqKWRAg1Zgl"
   },
   "source": [
    "# Computer Vision Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEuy0VpZ1Zgm"
   },
   "source": [
    "## Distraction detection during driving\n",
    "\n",
    "The main goal of this notebook is to show how can we detect the distraction of a driver using a dataset of thousand of driver images.\n",
    "More precisely we want to classify the activity the driver is performing (driving, texting, talking, operating the radio etc)\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* [Part 1 : Loading Dataset ](#chapter1)\n",
    "    \n",
    "* [Part 2 : EDA](#chapter2)\n",
    "\n",
    "* [Part 3 : Performing a CNN model for classification](#chapter3)\n",
    "\n",
    "* [Part 4 : Data augmentation for increase robustness](#chapter4)\n",
    "\n",
    "* [Part 5 : Transfer Learning for increasing accuracy](#chapter4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLfWr0UU1Zgn"
   },
   "source": [
    "### Technology used :\n",
    "- Python libraries : OpenCV, Tenserflow, Scikit Learn, Pandas,...\n",
    "- Computer vision techniques : CNN, Data Augmentation, Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrKoAJfV1Zgo"
   },
   "source": [
    "## Dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SieJ2qzB1Zgo"
   },
   "outputs": [],
   "source": [
    "The initial Dataset is composed of a thousand of images labelized as above. The goal of this notebook is to show how to classify them using computer vision techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tno2HHAm1Zgp"
   },
   "source": [
    "## Some check about libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-10T07:04:35.282024Z",
     "iopub.status.busy": "2021-10-10T07:04:35.281607Z",
     "iopub.status.idle": "2021-10-10T07:04:47.743582Z",
     "shell.execute_reply": "2021-10-10T07:04:47.742587Z",
     "shell.execute_reply.started": "2021-10-10T07:04:35.281995Z"
    },
    "id": "Z4ykLiwK1Zgp",
    "outputId": "b0309452-04f0-4acc-ec8a-aa492fa0f1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-10T07:04:47.745645Z",
     "iopub.status.busy": "2021-10-10T07:04:47.745422Z",
     "iopub.status.idle": "2021-10-10T07:06:23.064691Z",
     "shell.execute_reply": "2021-10-10T07:06:23.063255Z",
     "shell.execute_reply.started": "2021-10-10T07:04:47.745618Z"
    },
    "id": "VqZjlyDG1Zgq",
    "outputId": "c8b31021-2a1a-4d09-ad61-bce366658e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
      "\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 66.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 48.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 62.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
      "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
      "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
      "Successfully installed gast-0.4.0 keras-2.10.0 tensorboard-2.10.0 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-10T07:06:23.068829Z",
     "iopub.status.busy": "2021-10-10T07:06:23.067727Z",
     "iopub.status.idle": "2021-10-10T07:07:28.575873Z",
     "shell.execute_reply": "2021-10-10T07:07:28.574994Z",
     "shell.execute_reply.started": "2021-10-10T07:06:23.068784Z"
    },
    "id": "3fGSMN4B1Zgq",
    "outputId": "541b6051-9f18-4edf-acac-2da981debf89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.48.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0.7)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.2.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.6.15)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.10.0\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QpCnHCf1Zgq"
   },
   "source": [
    "## Part 1 : Loading Dataset  <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:07:33.253658Z",
     "iopub.status.busy": "2021-10-10T07:07:33.253337Z",
     "iopub.status.idle": "2021-10-10T07:07:37.108066Z",
     "shell.execute_reply": "2021-10-10T07:07:37.107262Z",
     "shell.execute_reply.started": "2021-10-10T07:07:33.253621Z"
    },
    "id": "GHDzliGt1Zgr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import tensorflow\n",
    "import datetime\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Rq_YY0ujA4pj",
    "outputId": "cb162e80-0448-4463-cc1a-6f3ae54df326"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e0d7d147-2608-4842-84d5-a253e4fbd50d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0d7d147-2608-4842-84d5-a253e4fbd50d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e0d7d147-2608-4842-84d5-a253e4fbd50d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e0d7d147-2608-4842-84d5-a253e4fbd50d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\n",
    "dataset = pd.read_csv('/driver_imgs_list.csv')\n",
    "\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-10T07:07:44.424975Z",
     "iopub.status.busy": "2021-10-10T07:07:44.424706Z",
     "iopub.status.idle": "2021-10-10T07:07:44.463936Z",
     "shell.execute_reply": "2021-10-10T07:07:44.46306Z",
     "shell.execute_reply.started": "2021-10-10T07:07:44.424948Z"
    },
    "id": "U8ct3VRE1Zgr",
    "outputId": "25095277-11f9-4685-9b08-c7e571f49dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are :  26  unique drivers\n",
      "There is a mean of  862  images by driver.\n"
     ]
    }
   ],
   "source": [
    "# Groupby subjects\n",
    "by_drivers = dataset.groupby('subject')\n",
    "# Groupby unique drivers\n",
    "unique_drivers = by_drivers.groups.keys() # drivers id\n",
    "print('There are : ',len(unique_drivers), ' unique drivers')\n",
    "print('There is a mean of ',round(dataset.groupby('subject').count()['classname'].mean()), ' images by driver.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01_vEXx0BkyD",
    "outputId": "58c94c9f-00cd-4909-ae25-15992e2c7f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP2HHeqN1Zgr"
   },
   "source": [
    "### Some functions for loading and normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBD7ht_o1Zgs"
   },
   "source": [
    "The 10 classes to classify are :\n",
    "- c0: safe driving\n",
    "- c1: texting - right\n",
    "- c2: talking on the phone - right\n",
    "- c3: texting - left\n",
    "- c4: talking on the phone - left\n",
    "- c5: operating the radio\n",
    "- c6: drinking\n",
    "- c7: reaching behind\n",
    "- c8: hair and makeup\n",
    "- c9: talking to passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:07:44.46585Z",
     "iopub.status.busy": "2021-10-10T07:07:44.465619Z",
     "iopub.status.idle": "2021-10-10T07:07:44.469922Z",
     "shell.execute_reply": "2021-10-10T07:07:44.469163Z",
     "shell.execute_reply.started": "2021-10-10T07:07:44.465824Z"
    },
    "id": "wPNMVtXe1Zgs"
   },
   "outputs": [],
   "source": [
    "NUMBER_CLASSES = 10 # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:07:44.471644Z",
     "iopub.status.busy": "2021-10-10T07:07:44.471431Z",
     "iopub.status.idle": "2021-10-10T07:07:44.494821Z",
     "shell.execute_reply": "2021-10-10T07:07:44.493831Z",
     "shell.execute_reply.started": "2021-10-10T07:07:44.471619Z"
    },
    "id": "-XwlZUrm1Zgs"
   },
   "outputs": [],
   "source": [
    "# Read with opencv\n",
    "def get_cv2_image(path, img_rows, img_cols, color_type=3):\n",
    "    \"\"\"\n",
    "    Function that return an opencv image from the path and the right number of dimension\n",
    "    \"\"\"\n",
    "    if color_type == 1: # Loading as Grayscale image\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    elif color_type == 3: # Loading as color image\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (img_rows, img_cols)) # Reduce size\n",
    "    return img\n",
    "\n",
    "# Loading Training dataset\n",
    "def load_train(img_rows, img_cols, color_type=3):\n",
    "    \"\"\"\n",
    "    Return train images and train labels from the original path\n",
    "    \"\"\"\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # Loop over the training folder\n",
    "    for classed in tqdm(range(NUMBER_CLASSES)):\n",
    "        print('Loading directory c{}'.format(classed))\n",
    "        files = glob(os.path.join('/driver_imgs_list.csv' + str(classed), '*.jpg'))\n",
    "        for file in files:\n",
    "            img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "            train_images.append(img)\n",
    "            train_labels.append(classed)\n",
    "    return train_images, train_labels\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type):\n",
    "    \"\"\"\n",
    "    Load + categorical + split\n",
    "    \"\"\"\n",
    "    X, labels = load_train(img_rows, img_cols, color_type)\n",
    "    y = np_utils.to_categorical(labels, 10) #categorical train label\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # split into train and test\n",
    "    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Loading validation dataset\n",
    "def load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n",
    "    \"\"\"\n",
    "    Same as above but for validation dataset\n",
    "    \"\"\"\n",
    "    path = os.path.join('/driver_imgs_list.csv', '*.jpg')\n",
    "    files = sorted(glob(path))\n",
    "    X_test, X_test_id = [], []\n",
    "    total = 0\n",
    "    files_size = len(files)\n",
    "    for file in tqdm(files):\n",
    "        if total >= size or total >= files_size:\n",
    "            break\n",
    "        file_base = os.path.basename(file)\n",
    "        img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(file_base)\n",
    "        total += 1\n",
    "    return X_test, X_test_id\n",
    "\n",
    "def read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n",
    "    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n",
    "    return test_data, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:07:44.496968Z",
     "iopub.status.busy": "2021-10-10T07:07:44.496374Z",
     "iopub.status.idle": "2021-10-10T07:12:18.692754Z",
     "shell.execute_reply": "2021-10-10T07:12:18.691631Z",
     "shell.execute_reply.started": "2021-10-10T07:07:44.496925Z"
    },
    "id": "KtkJdw8q1Zgt"
   },
   "outputs": [],
   "source": [
    "img_rows = 64 # dimension of images\n",
    "img_cols = 64\n",
    "color_type = 1 # grey\n",
    "nb_test_samples = 200\n",
    "\n",
    "# loading train images\n",
    "x_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "\n",
    "# loading validation images\n",
    "test_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98tlSGha1Zgt"
   },
   "source": [
    "## Part 2 : EDA  <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:18.695239Z",
     "iopub.status.busy": "2021-10-10T07:12:18.695013Z",
     "iopub.status.idle": "2021-10-10T07:12:19.051621Z",
     "shell.execute_reply": "2021-10-10T07:12:19.050746Z",
     "shell.execute_reply.started": "2021-10-10T07:12:18.6952Z"
    },
    "id": "GjYTDyUn1Zgt"
   },
   "outputs": [],
   "source": [
    "# Statistics\n",
    "# Load the list of names\n",
    "names = [item[17:19] for item in sorted(glob(\"../input/state-farm-distracted-driver-detection/imgs/train/*/\"))]\n",
    "test_files_size = len(np.array(glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg'))))\n",
    "x_train_size = len(x_train)\n",
    "categories_size = len(names)\n",
    "x_test_size = len(x_test)\n",
    "print('There are %s total images.\\n' % (test_files_size + x_train_size + x_test_size))\n",
    "print('There are %d training images.' % x_train_size)\n",
    "print('There are %d total training categories.' % categories_size)\n",
    "print('There are %d validation images.' % x_test_size)\n",
    "print('There are %d test images.'% test_files_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDCbTt2T1Zgt"
   },
   "source": [
    "### Data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcIWTiuB1Zgu"
   },
   "source": [
    "Number of images by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:19.05358Z",
     "iopub.status.busy": "2021-10-10T07:12:19.05326Z",
     "iopub.status.idle": "2021-10-10T07:12:21.872517Z",
     "shell.execute_reply": "2021-10-10T07:12:21.871498Z",
     "shell.execute_reply.started": "2021-10-10T07:12:19.053541Z"
    },
    "id": "U8TDgA1g1Zgu"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(dataset, x=\"classname\", color=\"classname\", title=\"Number of images by categories \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a3wgBef1Zgu"
   },
   "source": [
    "--> It is well distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:21.873938Z",
     "iopub.status.busy": "2021-10-10T07:12:21.873713Z",
     "iopub.status.idle": "2021-10-10T07:12:22.071848Z",
     "shell.execute_reply": "2021-10-10T07:12:22.071021Z",
     "shell.execute_reply.started": "2021-10-10T07:12:21.873912Z"
    },
    "id": "jzF4cywF1Zgv"
   },
   "outputs": [],
   "source": [
    "# Find the frequency of images per driver\n",
    "drivers_id = pd.DataFrame((dataset['subject'].value_counts()).reset_index())\n",
    "drivers_id.columns = ['driver_id', 'Counts']\n",
    "px.histogram(drivers_id, x=\"driver_id\",y=\"Counts\" ,color=\"driver_id\", title=\"Number of images by subjects \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7B2hmku1Zgv"
   },
   "source": [
    "### Images overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZQuJjIa1Zgv"
   },
   "source": [
    "Let's take a look at the various images in the dataset.\n",
    "* I'll plot an image for each of the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:22.073973Z",
     "iopub.status.busy": "2021-10-10T07:12:22.073163Z",
     "iopub.status.idle": "2021-10-10T07:12:24.462929Z",
     "shell.execute_reply": "2021-10-10T07:12:24.46204Z",
     "shell.execute_reply.started": "2021-10-10T07:12:22.073921Z"
    },
    "id": "OhqQ0hxF1Zgv"
   },
   "outputs": [],
   "source": [
    "activity_map = {'c0': 'Safe driving',\n",
    "                'c1': 'Texting - right',\n",
    "                'c2': 'Talking on the phone - right',\n",
    "                'c3': 'Texting - left',\n",
    "                'c4': 'Talking on the phone - left',\n",
    "                'c5': 'Operating the radio',\n",
    "                'c6': 'Drinking',\n",
    "                'c7': 'Reaching behind',\n",
    "                'c8': 'Hair and makeup',\n",
    "                'c9': 'Talking to passenger'}\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12, 20))\n",
    "image_count = 1\n",
    "BASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "            else:\n",
    "                fig = plt.subplot(5, 2, image_count)\n",
    "                image_count += 1\n",
    "                image = mpimg.imread(BASE_URL + directory + '/' + file)\n",
    "                plt.imshow(image)\n",
    "                plt.title(activity_map[directory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:24.465046Z",
     "iopub.status.busy": "2021-10-10T07:12:24.464411Z",
     "iopub.status.idle": "2021-10-10T07:12:24.474442Z",
     "shell.execute_reply": "2021-10-10T07:12:24.473577Z",
     "shell.execute_reply.started": "2021-10-10T07:12:24.465008Z"
    },
    "id": "jSr8aNPK1Zgw"
   },
   "outputs": [],
   "source": [
    "def create_submission(predictions, test_id, info):\n",
    "    \"\"\"\n",
    "    Submission function for participating to the competition\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result.loc[:, 'img'] = pd.Series(test_id, index=result.index)\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    if not os.path.isdir('kaggle_submissions'):\n",
    "        os.mkdir('kaggle_submissions')\n",
    "\n",
    "    suffix = \"{}_{}\".format(info,str(now.strftime(\"%Y-%m-%d-%H-%M\")))\n",
    "    sub_file = os.path.join('kaggle_submissions', 'submission_' + suffix + '.csv')\n",
    "\n",
    "    result.to_csv(sub_file, index=False)\n",
    "\n",
    "    return sub_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIDIz2YJ1Zgw"
   },
   "source": [
    "Create a vanilla CNN model\n",
    "Building the model\n",
    "I'll develop the model with a total of 4 Convolutional layers, then a Flatten layer and then 2 Dense layers. I'll use the optimizer as rmsprop, and loss as categorical_crossentropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyTNL-EZ1Zgw"
   },
   "source": [
    "## Part 3 : CNN Model  <a class=\"anchor\" id=\"chapter3\"></a>\n",
    "Architecture :\n",
    "- 3 Convolutionnal layers (with Relu, Maxpooling and dropout)\n",
    "- A flatten layer\n",
    "- 2 Dense layers with Relu and Dropouts\n",
    "- 1 Dense layer with softmax for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:24.476379Z",
     "iopub.status.busy": "2021-10-10T07:12:24.476127Z",
     "iopub.status.idle": "2021-10-10T07:12:24.485627Z",
     "shell.execute_reply": "2021-10-10T07:12:24.484796Z",
     "shell.execute_reply.started": "2021-10-10T07:12:24.476351Z"
    },
    "id": "U94KFSUi1Zgw"
   },
   "outputs": [],
   "source": [
    "# Number of batch size and epochs\n",
    "batch_size = 40 #40\n",
    "nb_epoch = 6 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:24.487371Z",
     "iopub.status.busy": "2021-10-10T07:12:24.486917Z",
     "iopub.status.idle": "2021-10-10T07:12:24.497745Z",
     "shell.execute_reply": "2021-10-10T07:12:24.497128Z",
     "shell.execute_reply.started": "2021-10-10T07:12:24.487338Z"
    },
    "id": "IrCPNAA_1Zgw"
   },
   "outputs": [],
   "source": [
    "models_dir = \"saved_models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights_best_vanilla.hdf5',\n",
    "                               monitor='val_loss', mode='min',\n",
    "                               verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "#callbacks = [checkpointer, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:24.499353Z",
     "iopub.status.busy": "2021-10-10T07:12:24.498941Z",
     "iopub.status.idle": "2021-10-10T07:12:24.756554Z",
     "shell.execute_reply": "2021-10-10T07:12:24.755711Z",
     "shell.execute_reply.started": "2021-10-10T07:12:24.499322Z"
    },
    "id": "G-JyjJK_1Zgw"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    ## CNN 1\n",
    "    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization(axis = 3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    ## CNN 2\n",
    "    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization(axis = 3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    ## CNN 3\n",
    "    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization(axis = 3))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    ## Output\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:24.758074Z",
     "iopub.status.busy": "2021-10-10T07:12:24.75785Z",
     "iopub.status.idle": "2021-10-10T07:12:25.044974Z",
     "shell.execute_reply": "2021-10-10T07:12:25.04417Z",
     "shell.execute_reply.started": "2021-10-10T07:12:24.758049Z"
    },
    "id": "jv0aMjTc1Zgx"
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "# More details about the layers\n",
    "model.summary()\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeEgTtjI1Zgx"
   },
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:12:25.048028Z",
     "iopub.status.busy": "2021-10-10T07:12:25.047798Z",
     "iopub.status.idle": "2021-10-10T07:46:43.098775Z",
     "shell.execute_reply": "2021-10-10T07:46:43.097584Z",
     "shell.execute_reply.started": "2021-10-10T07:12:25.048002Z"
    },
    "id": "AAiR2sYH1Zgx"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "#model.load_weights('saved_models/weights_best_vanilla.hdf5')\n",
    "print('History of the training',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:46:43.101247Z",
     "iopub.status.busy": "2021-10-10T07:46:43.10097Z",
     "iopub.status.idle": "2021-10-10T07:46:43.483586Z",
     "shell.execute_reply": "2021-10-10T07:46:43.482599Z",
     "shell.execute_reply.started": "2021-10-10T07:46:43.101198Z"
    },
    "id": "A5UjB4Es1Zgx"
   },
   "outputs": [],
   "source": [
    "def plot_train_history(history):\n",
    "    \"\"\"\n",
    "    Plot the validation accuracy and validation loss over epochs\n",
    "    \"\"\"\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRTCT-6H1Zgx"
   },
   "source": [
    "#### Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:46:43.485445Z",
     "iopub.status.busy": "2021-10-10T07:46:43.485111Z",
     "iopub.status.idle": "2021-10-10T07:46:43.493188Z",
     "shell.execute_reply": "2021-10-10T07:46:43.4923Z",
     "shell.execute_reply.started": "2021-10-10T07:46:43.485412Z"
    },
    "id": "Z-OdO4L41Zgx"
   },
   "outputs": [],
   "source": [
    "def plot_test_class(model, test_files, image_number, color_type=1):\n",
    "    \"\"\"\n",
    "    Function that tests or model on test images and show the results\n",
    "    \"\"\"\n",
    "    img_brute = test_files[image_number]\n",
    "    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n",
    "    plt.imshow(img_brute, cmap='gray')\n",
    "\n",
    "    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n",
    "\n",
    "    y_prediction = model.predict(new_img, batch_size=batch_size, verbose=1)\n",
    "    print('Y prediction: {}'.format(y_prediction))\n",
    "    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:46:43.495196Z",
     "iopub.status.busy": "2021-10-10T07:46:43.494862Z",
     "iopub.status.idle": "2021-10-10T07:47:01.292802Z",
     "shell.execute_reply": "2021-10-10T07:47:01.291883Z",
     "shell.execute_reply.started": "2021-10-10T07:46:43.495145Z"
    },
    "id": "6s4XybNu1Zgy"
   },
   "outputs": [],
   "source": [
    "score1 = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:47:01.294535Z",
     "iopub.status.busy": "2021-10-10T07:47:01.294279Z",
     "iopub.status.idle": "2021-10-10T07:47:01.300919Z",
     "shell.execute_reply": "2021-10-10T07:47:01.300253Z",
     "shell.execute_reply.started": "2021-10-10T07:47:01.294507Z"
    },
    "id": "Jpsm7fmM1Zgy"
   },
   "outputs": [],
   "source": [
    "print('Loss: ', score1[0])\n",
    "print('Accuracy: ', score1[1]*100, ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:47:01.302758Z",
     "iopub.status.busy": "2021-10-10T07:47:01.302297Z",
     "iopub.status.idle": "2021-10-10T07:47:03.988936Z",
     "shell.execute_reply": "2021-10-10T07:47:03.98809Z",
     "shell.execute_reply.started": "2021-10-10T07:47:01.302728Z"
    },
    "id": "pyp75gYx1Zgy"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_test_class(model, test_files, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnkkH44l1Zgy"
   },
   "source": [
    "#### Good accuracy but we can do better !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peJy_V2A1Zgy"
   },
   "source": [
    "## Part 4 : Data Augmentation  <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbTjV3wH1Zgy"
   },
   "source": [
    "Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset. Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n",
    "\n",
    "For that we will use the ImageDataGenerator from keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddOnF60X1Zgy"
   },
   "source": [
    "Example of data augmentation (Shift, sampling, resizing etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8bo7O9l1Zgy"
   },
   "source": [
    "So now we create another model with data augmentation with the input in order to increase accuracy.\n",
    "We generate more images using ImageDataGenerator and split the training data into 80% train and 20% validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:47:03.990758Z",
     "iopub.status.busy": "2021-10-10T07:47:03.990527Z",
     "iopub.status.idle": "2021-10-10T07:47:03.996899Z",
     "shell.execute_reply": "2021-10-10T07:47:03.995898Z",
     "shell.execute_reply.started": "2021-10-10T07:47:03.990731Z"
    },
    "id": "6vqmBrhU1Zgy"
   },
   "outputs": [],
   "source": [
    "# Using ImageDataGenerator from keras\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:47:03.998271Z",
     "iopub.status.busy": "2021-10-10T07:47:03.998033Z",
     "iopub.status.idle": "2021-10-10T07:47:04.261058Z",
     "shell.execute_reply": "2021-10-10T07:47:04.260119Z",
     "shell.execute_reply.started": "2021-10-10T07:47:03.998242Z"
    },
    "id": "62uZ-Elh1Zgz"
   },
   "outputs": [],
   "source": [
    "nb_train_samples = x_train.shape[0]\n",
    "nb_validation_samples = x_test.shape[0]\n",
    "training_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "validation_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5-pRFt_1Zgz"
   },
   "source": [
    "### Training with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T07:47:04.263143Z",
     "iopub.status.busy": "2021-10-10T07:47:04.262876Z",
     "iopub.status.idle": "2021-10-10T08:21:14.601429Z",
     "shell.execute_reply": "2021-10-10T08:21:14.598823Z",
     "shell.execute_reply.started": "2021-10-10T07:47:04.263113Z"
    },
    "id": "IjZjVc3O1Zgz"
   },
   "outputs": [],
   "source": [
    "#checkpoint = ModelCheckpoint('saved_models/weights_best_vanilla.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history_v2 = model.fit_generator(training_generator,\n",
    "                         steps_per_epoch = nb_train_samples // batch_size,\n",
    "                         epochs = nb_epoch,\n",
    "                         verbose = 1,\n",
    "                         validation_data = validation_generator,\n",
    "                         validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:21:14.609166Z",
     "iopub.status.busy": "2021-10-10T08:21:14.6087Z",
     "iopub.status.idle": "2021-10-10T08:21:15.10281Z",
     "shell.execute_reply": "2021-10-10T08:21:15.101416Z",
     "shell.execute_reply.started": "2021-10-10T08:21:14.609123Z"
    },
    "id": "gmhM89rm1Zgz"
   },
   "outputs": [],
   "source": [
    "#model2.load_weights('saved_models/weights_best_va nilla.hdf5')\n",
    "plot_train_history(history_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:21:15.104915Z",
     "iopub.status.busy": "2021-10-10T08:21:15.104531Z",
     "iopub.status.idle": "2021-10-10T08:21:32.752899Z",
     "shell.execute_reply": "2021-10-10T08:21:32.751664Z",
     "shell.execute_reply.started": "2021-10-10T08:21:15.104872Z"
    },
    "id": "VdqZFOWz1Zgz"
   },
   "outputs": [],
   "source": [
    "# Evaluate and compare the performance of the new model\n",
    "score2 = model.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\n",
    "print(\"Loss for model 1\",score1[0])\n",
    "print(\"Loss for model 2 (data augmentation):\", score2[0])\n",
    "\n",
    "print(\"Test accuracy for model 1\",score1[1])\n",
    "print(\"Test accuracy for model 2 (data augmentation):\", score2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bb0YCzJZ1Zgz"
   },
   "source": [
    "### Conclusion for Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXNXSVK91Zgz"
   },
   "source": [
    "#### Data augmentation makes our model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cebvbfum1Zgz"
   },
   "source": [
    "## Part 5 : Transfer Learning with VGG  <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FXXqog81Zg0"
   },
   "source": [
    "- Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.\n",
    "- That's why we train a CNN with Transfer Learning (VGG, MobileNet) in order to reduce training time without sacrificing accuracy.\n",
    "- VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:21:32.754764Z",
     "iopub.status.busy": "2021-10-10T08:21:32.754496Z",
     "iopub.status.idle": "2021-10-10T08:21:32.765478Z",
     "shell.execute_reply": "2021-10-10T08:21:32.764534Z",
     "shell.execute_reply.started": "2021-10-10T08:21:32.754736Z"
    },
    "id": "SLCjSXvZ1Zg0"
   },
   "outputs": [],
   "source": [
    "def vgg_std16_model(img_rows, img_cols, color_type=3):\n",
    "    \"\"\"\n",
    "    Architecture and adaptation of the VGG16 for our project\n",
    "    \"\"\"\n",
    "    nb_classes = 10\n",
    "    # Remove fully connected layer and replace\n",
    "    vgg16_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "    for layer in vgg16_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = vgg16_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(nb_classes, activation = 'softmax')(x) # add dense layer with 10 neurons and activation softmax\n",
    "    model = Model(vgg16_model.input,predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:21:32.769237Z",
     "iopub.status.busy": "2021-10-10T08:21:32.768599Z",
     "iopub.status.idle": "2021-10-10T08:21:34.294191Z",
     "shell.execute_reply": "2021-10-10T08:21:34.292865Z",
     "shell.execute_reply.started": "2021-10-10T08:21:32.769181Z"
    },
    "id": "YveBfdmE1Zg0"
   },
   "outputs": [],
   "source": [
    "# Load the VGG16 network\n",
    "print(\"Loading network...\")\n",
    "model_vgg16 = vgg_std16_model(img_rows, img_cols)\n",
    "model_vgg16.summary()\n",
    "model_vgg16.compile(loss='categorical_crossentropy',\n",
    "                         optimizer='rmsprop',\n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:21:34.296044Z",
     "iopub.status.busy": "2021-10-10T08:21:34.295806Z",
     "iopub.status.idle": "2021-10-10T08:25:42.033915Z",
     "shell.execute_reply": "2021-10-10T08:25:42.032422Z",
     "shell.execute_reply.started": "2021-10-10T08:21:34.296017Z"
    },
    "id": "X_yApWAy1Zg0"
   },
   "outputs": [],
   "source": [
    "training_generator = train_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train',\n",
    "                                                 target_size = (img_rows, img_cols),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 class_mode='categorical', subset=\"training\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/test',\n",
    "                                                   target_size = (img_rows, img_cols),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   shuffle=False,\n",
    "                                                   class_mode='categorical', subset=\"validation\")\n",
    "nb_train_samples = 17943\n",
    "nb_validation_samples = 4481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:25:42.035794Z",
     "iopub.status.busy": "2021-10-10T08:25:42.035479Z",
     "iopub.status.idle": "2021-10-10T08:25:42.040106Z",
     "shell.execute_reply": "2021-10-10T08:25:42.039483Z",
     "shell.execute_reply.started": "2021-10-10T08:25:42.035758Z"
    },
    "id": "zlaEo_Ar1Zg0"
   },
   "outputs": [],
   "source": [
    "epoch=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:25:42.041961Z",
     "iopub.status.busy": "2021-10-10T08:25:42.041487Z",
     "iopub.status.idle": "2021-10-10T09:11:56.370839Z",
     "shell.execute_reply": "2021-10-10T09:11:56.369751Z",
     "shell.execute_reply.started": "2021-10-10T08:25:42.041928Z"
    },
    "id": "Ps92_wSQ1Zg1"
   },
   "outputs": [],
   "source": [
    "# Training the new Model\n",
    "#checkpoint = ModelCheckpoint('saved_models/weights_best_vgg16.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history_v3 = model_vgg16.fit_generator(training_generator,\n",
    "                         steps_per_epoch = nb_train_samples // batch_size,\n",
    "                         epochs = epoch,\n",
    "                         verbose = 1,\n",
    "                         validation_data = validation_generator,\n",
    "                         validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T09:11:56.374702Z",
     "iopub.status.busy": "2021-10-10T09:11:56.374249Z",
     "iopub.status.idle": "2021-10-10T09:11:57.163559Z",
     "shell.execute_reply": "2021-10-10T09:11:57.161916Z",
     "shell.execute_reply.started": "2021-10-10T09:11:56.374652Z"
    },
    "id": "IEfzOxt51Zg1"
   },
   "outputs": [],
   "source": [
    "#model_vgg16.load_weights('saved_models/weights_best_vgg16.hdf5')\n",
    "plot_train_history(history_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-10T09:11:57.164618Z",
     "iopub.status.idle": "2021-10-10T09:11:57.165044Z",
     "shell.execute_reply": "2021-10-10T09:11:57.164858Z",
     "shell.execute_reply.started": "2021-10-10T09:11:57.164838Z"
    },
    "id": "8x7821Q01Zg1"
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance of the new model with Transfer learning\n",
    "score3 = model_vgg16.evaluate_generator(validation_generator, nb_validation_samples // batch_size, verbose = 1)\n",
    "\n",
    "print(\"Test Score with simple CNN:\", score1[0])\n",
    "print(\"Test Accuracy with simple CNN\", score1[1])\n",
    "print('--------------------------------------')\n",
    "print(\"Test Score with Data Augmentation:\", score2[0])\n",
    "print(\"Test Accuracy with Data Augmentation:\", score2[1])\n",
    "print('--------------------------------------')\n",
    "print(\"Test Score with Transfer Learning:\", score3[0])\n",
    "print(\"Test Accuracy with Transfer Learning:\", score3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHwHUbo21Zg1"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mecF7kTl1Zg1"
   },
   "source": [
    "* ### CNN are really powerfull in computer vision in order to classify images. (We predict well more than 90% of the images)\n",
    "* ### And differents techniques exist in order to improve its performance like Data augmentation and Transfer learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UDCbTt2T1Zgt",
    "G7B2hmku1Zgv",
    "DeEgTtjI1Zgx",
    "dRTCT-6H1Zgx",
    "SnkkH44l1Zgy",
    "J5-pRFt_1Zgz",
    "Bb0YCzJZ1Zgz",
    "AXNXSVK91Zgz",
    "mecF7kTl1Zg1"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
